{% block body %}

<div class="center">
<h2 class="mt-3">Credits</h2>

<p class="lead">
    This project was done as part of the "Reinforcement Learning" course at the University of Amsterdam in the academic year of 2020-2021. <br>
    The contributors are Angelo Groot, Jordan Earle, Melle Vessies and Reitze Jansen.
</p>
<h2 class="mt-3">References</h2>

<div class="row">
    <div class="col-sm-10 textbox">
        <ol>
            <li><div class="reference" id="ref1"><a href="https://arxiv.org/abs/1812.02648"> Van Hasselt, H., Doron, Y., Strub, F., Hessel, M., Sonnerat, N., & Modayil, J. (2018). Deep reinforcement learning and the deadly triad. arXiv preprint arXiv:1812.02648. </a></div></li>
            <li><div class="reference" id="ref2"><a href="http://incompleteideas.net/book/the-book-2nd.html"> Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press.</a></div></li>
            <li><div class="reference" id="ref3"><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.7501&rep=rep1&type=pdf"> Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine learning, 8(3-4), 279-292.</a></div></li>
            <li><div class="reference" id="ref4"><a href="http://www.incompleteideas.net/lin-92.pdf"> Lin, L. J. (1992). Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine learning, 8(3-4), 293-321. </a></div></li>
            <li><div class="reference" id="ref5"><a href="https://gym.openai.com/"> OpenAI Gym </a></div></li>
            <li><div class="reference" id="ref6"><a href="https://arxiv.org/pdf/1312.5602.pdf?"> Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602. </a></div></li>
            <li><div class="reference" id="ref7"><a href="https://arxiv.org/pdf/1511.05952.pdf "> Schaul, T., Quan, J., Antonoglou, I., & Silver, D. (2015). Prioritized experience replay. arXiv preprint arXiv:1511.05952. </a></div></li>
            <li><div class="reference" id="ref8"><a href="https://arxiv.org/pdf/1709.06560.pdf"> Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., & Meger, D. (2017). Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560. </a></div></li>
            <li><div class="reference" id="ref9"><a href="https://github.com/pytorch/pytorch"> https://github.com/pytorch </a></div></li>
            <li><div class="reference" id="ref10"><a href="https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python" >Ankit Choudhary's A Hands-On Introduction to Deep Q-Learning using OpenAI Gym in Python </a></div></li>
            <li><div class="reference" id="ref11"><a href="https://www.youtube.com/watch?v=TmPfTpjtdgg."> Deepminds Atari Breakout Video </a></div></li>
            <li><div class="reference" id="ref12"><a href="https://www.datascienceassn.org/sites/default/files/Human-level%20Control%20Through%20Deep%20Reinforcement%20Learning.pdf"> Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). Human-level control through deep reinforcement learning. nature, 518(7540), 529-533.</a></div></li>
        </ol>
    </div>
</div>

{% endblock %}
